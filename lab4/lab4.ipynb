{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 63)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Natural</th>\n",
       "      <th>language</th>\n",
       "      <th>processing</th>\n",
       "      <th>(NLP)</th>\n",
       "      <th>is</th>\n",
       "      <th>a</th>\n",
       "      <th>subfield</th>\n",
       "      <th>of</th>\n",
       "      <th>linguistics</th>\n",
       "      <th>computer</th>\n",
       "      <th>...</th>\n",
       "      <th>categorize</th>\n",
       "      <th>organize</th>\n",
       "      <th>themselves</th>\n",
       "      <th>Challenges</th>\n",
       "      <th>frequently</th>\n",
       "      <th>involve</th>\n",
       "      <th>speech</th>\n",
       "      <th>recognition</th>\n",
       "      <th>understanding</th>\n",
       "      <th>generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Natural  language  processing  (NLP)  is  a  subfield  of  linguistics  \\\n",
       "sent0        1         1           1      1   1  1         1   1            1   \n",
       "sent1        0         1           0      0   1  1         0   1            0   \n",
       "sent2        0         0           0      0   0  0         0   0            0   \n",
       "sent3        0         1           1      0   0  0         0   0            0   \n",
       "sent4        0         0           0      0   0  0         0   0            0   \n",
       "\n",
       "       computer  ...  categorize  organize  themselves  Challenges  \\\n",
       "sent0         1  ...           0         0           0           0   \n",
       "sent1         1  ...           0         0           0           0   \n",
       "sent2         0  ...           1         1           1           0   \n",
       "sent3         0  ...           0         0           0           1   \n",
       "sent4         0  ...           0         0           0           0   \n",
       "\n",
       "       frequently  involve  speech  recognition  understanding  generation  \n",
       "sent0           0        0       0            0              0           0  \n",
       "sent1           0        0       0            0              0           0  \n",
       "sent2           0        0       0            0              0           0  \n",
       "sent3           1        1       1            1              1           1  \n",
       "sent4           0        0       0            0              0           0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a bag of words for sentences in the file 'Corpus.txt'\n",
    "# Filter .!? etc. from the sentences\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "file = open('Corpus.txt', 'r')\n",
    "text = file.read()\n",
    "\n",
    "sentences = text.split('.')\n",
    "\n",
    "corpus = {}\n",
    "\n",
    "pattern = re.compile(r\"([-\\s.,;!?])+\")\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    tokens = pattern.split(sentence)\n",
    "    tokens = [x for x in tokens if x and x not in '- \\t\\n.,;!?']\n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in tokens)\n",
    "\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 48)\n",
      "sent0 vs sent1\n",
      "2\n",
      "sent0 vs sent2\n",
      "0\n",
      "sent0 vs sent3\n",
      "3\n",
      "sent0 vs sent4\n",
      "0\n",
      "sent1 vs sent0\n",
      "2\n",
      "sent1 vs sent2\n",
      "2\n",
      "sent1 vs sent3\n",
      "1\n",
      "sent1 vs sent4\n",
      "0\n",
      "sent2 vs sent0\n",
      "0\n",
      "sent2 vs sent1\n",
      "2\n",
      "sent2 vs sent3\n",
      "0\n",
      "sent2 vs sent4\n",
      "0\n",
      "sent3 vs sent0\n",
      "3\n",
      "sent3 vs sent1\n",
      "1\n",
      "sent3 vs sent2\n",
      "0\n",
      "sent3 vs sent4\n",
      "0\n",
      "sent4 vs sent0\n",
      "0\n",
      "sent4 vs sent1\n",
      "0\n",
      "sent4 vs sent2\n",
      "0\n",
      "sent4 vs sent3\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kacper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# calculate overlap of each sentence in the file 'Corpus.txt'\n",
    "\n",
    "for index1, row1 in df.iterrows():\n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 != index2:\n",
    "            print(index1, 'vs', index2)\n",
    "            print(row1.dot(row2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 48)\n",
      "sent0 vs sent0\n",
      "22\n",
      "sent0 vs sent1\n",
      "2\n",
      "sent0 vs sent2\n",
      "0\n",
      "sent0 vs sent3\n",
      "3\n",
      "sent0 vs sent4\n",
      "0\n",
      "sent1 vs sent1\n",
      "12\n",
      "sent1 vs sent2\n",
      "2\n",
      "sent1 vs sent3\n",
      "1\n",
      "sent1 vs sent4\n",
      "0\n",
      "sent2 vs sent2\n",
      "11\n",
      "sent2 vs sent3\n",
      "0\n",
      "sent2 vs sent4\n",
      "0\n",
      "sent3 vs sent3\n",
      "10\n",
      "sent3 vs sent4\n",
      "0\n",
      "sent4 vs sent4\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kacper\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# do the same as in previous task, but now remove stop words from the sentences\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    tokens = pattern.split(sentence)\n",
    "    tokens = [x for x in tokens if x and x not in '- \\t\\n.,;!?']\n",
    "    tokens = [x for x in tokens if x not in stop_words]\n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in tokens)\n",
    "\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "print(df.shape)\n",
    "df\n",
    "\n",
    "for index1, row1 in df.iterrows():\n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 <= index2:\n",
    "            print(index1, 'vs', index2)\n",
    "            print(row1.dot(row2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 45)\n",
      "sent0 vs sent0\n",
      "19\n",
      "sent0 vs sent1\n",
      "2\n",
      "sent0 vs sent2\n",
      "0\n",
      "sent0 vs sent3\n",
      "3\n",
      "sent0 vs sent4\n",
      "0\n",
      "sent1 vs sent1\n",
      "12\n",
      "sent1 vs sent2\n",
      "2\n",
      "sent1 vs sent3\n",
      "1\n",
      "sent1 vs sent4\n",
      "0\n",
      "sent2 vs sent2\n",
      "11\n",
      "sent2 vs sent3\n",
      "0\n",
      "sent2 vs sent4\n",
      "0\n",
      "sent3 vs sent3\n",
      "10\n",
      "sent3 vs sent4\n",
      "0\n",
      "sent4 vs sent4\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# do as above, but using Porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    tokens = pattern.split(sentence)\n",
    "    tokens = [x for x in tokens if x and x not in '- \\t\\n.,;!?']\n",
    "    tokens = [x for x in tokens if x not in stop_words]\n",
    "    tokens = [stemmer.stem(x) for x in tokens]\n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in tokens)\n",
    "\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "print(df.shape)\n",
    "df\n",
    "\n",
    "for index1, row1 in df.iterrows():\n",
    "    for index2, row2 in df.iterrows():\n",
    "        if index1 <= index2:\n",
    "            print(index1, 'vs', index2)\n",
    "            print(row1.dot(row2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacper\\AppData\\Local\\Temp\\ipykernel_11808\\1675745254.py:40: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df.groupby('sentiment').mean()['diff']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "-0.010638298   -0.345438\n",
       "-0.010752688    0.209447\n",
       "-0.021052632   -0.967553\n",
       "-0.021276596    0.400223\n",
       "-0.030927835    0.639572\n",
       "                  ...   \n",
       "3.445652174     2.951752\n",
       "3.45            3.028500\n",
       "3.47311828      2.539018\n",
       "3.489583333     2.621183\n",
       "3.55            2.757500\n",
       "Name: diff, Length: 968, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read 'TweeterSentiments.txt' and use VADER to determine sentiments. Compare with sentiments in the file. You can for examole calculate average difference per sentiment.\n",
    "\n",
    "# the second column contains the sentiment, the third column contains the tweet\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "file = open('TweeterSentiments.txt', 'r')\n",
    "text = file.read()\n",
    "\n",
    "sa = SentimentIntensityAnalyzer()\n",
    "\n",
    "# read the file into a dataframe\n",
    "tweets = pd.read_csv('TweeterSentiments.txt', sep='\\t', header=None, names=['id', 'sentiment', 'tweet'])\n",
    "\n",
    "print(tweets.head())\n",
    "\n",
    "vader_scores = [sa.polarity_scores(tweet) for tweet in tweets['tweet']]\n",
    "tweets['vader_scores'] = vader_scores\n",
    "tweets['diffeence'] = (tweets['sentiment']) - (tweets['sentiment'] - tweets['vader_scores']).abs()\n",
    "\n",
    "print('averaged difference per sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0abe801034007484f152c408f6878125c4d199d6c578a45ceffdae6ced931ee7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
