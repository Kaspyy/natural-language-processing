{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\n",
      "0.1965260161476905\n"
     ]
    }
   ],
   "source": [
    "# For a corpus:\n",
    "corpus = [\"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\", 'The goal is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them.', 'The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.', 'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.' ]\n",
    "\n",
    "# Find the best matching sentence for the question:\n",
    "query = \"What is NLP?\"\n",
    "\n",
    "# Use cosine similarity and TFIDF vectors (e.g. from sckikit-learn).\n",
    "from nltk.tokenize import casual_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tokenize the corpus and the query:\n",
    "corpus_tokens = [casual_tokenize(doc) for doc in corpus]\n",
    "query_tokens = casual_tokenize(query)\n",
    "\n",
    "# Create a TFIDF vectorizer:\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Create a TFIDF matrix for the corpus:\n",
    "corpus_tfidf = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Create a TFIDF matrix for the query:\n",
    "query_tfidf = vectorizer.transform([query])\n",
    "\n",
    "# Compute the cosine similarity between the query and the corpus:\n",
    "cosine_similarities = cosine_similarity(query_tfidf, corpus_tfidf).flatten()\n",
    "\n",
    "# Find the most similar sentence:\n",
    "most_similar = cosine_similarities.argmax()\n",
    "\n",
    "# Print the most similar sentence:\n",
    "print(corpus[most_similar])\n",
    "\n",
    "# Print the similarity score:\n",
    "print(cosine_similarities[most_similar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m conversation_tfidf \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform([pair[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m pair \u001b[39min\u001b[39;00m conversation])\n\u001b[0;32m     21\u001b[0m \u001b[39m# Compute similarities\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m cosine_similarities \u001b[39m=\u001b[39m cosine_similarity(conversation_tfidf, corpus_tfidf)\u001b[39m.\u001b[39mflatten()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Write a chatbot that reacts on specific dialog [[Question, Answer], ...]\n",
    "conversation = [[\"Hello\", \"Hi\"],[\"How are you?\", \"I am fine\"], [\"What is your name?\", \"My name is HAL\" ]]\n",
    "\n",
    "# You can follow:\n",
    "# 1. Create TFIDF vectors for each question (try without stop words first)\n",
    "# 2. Write REPL that reads question, convert it to TFIDF vector, compute cos similarity, finds best match, and returns answer to the best-matched question.\n",
    "\n",
    "from nltk.tokenize import casual_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Tokenize the conversation:\n",
    "conversation_tokens = [[casual_tokenize(doc) for doc in pair] for pair in conversation]\n",
    "\n",
    "# Create a TFIDF vectorizer:\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Create a TFIDF matrix for the conversation:\n",
    "conversation_tfidf = vectorizer.fit_transform([pair[0] for pair in conversation])\n",
    "\n",
    "# Compute similarities\n",
    "cosine_similarities = cosine_similarity(conversation_tfidf, corpus_tfidf).flatten()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0abe801034007484f152c408f6878125c4d199d6c578a45ceffdae6ced931ee7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
